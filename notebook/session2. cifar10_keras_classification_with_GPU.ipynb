{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Azure Developer Camp\n",
    "## AI & Machine Learning\n",
    "---\n",
    "\n",
    "### Session 2. Cifar10 Image Classification with Keras with GPU ğŸ˜\n",
    "\n",
    "* [Keras Document](http://keras.io/)  \n",
    "* [Cifar10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.GPU í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Backendì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ í™•ì¸\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì • ë””ë°”ì´ìŠ¤ ì‚¬ìš©\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "K.tf.device('/device:GPU:0')\n",
    "\n",
    "K._get_available_gpus() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1. Data Preprocessing\n",
    "### 1. Cifar10 ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ 60,000ì¥ì˜ ì´ë¯¸ì§€ë¡œ(163MB), ë‚´ë ¤ë°›ëŠ”ë° ëª‡ ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤.\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ë¥¼ í›ˆë ¨ì…‹ê³¼ ê²€ì¦ì…‹ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.(í›ˆë ¨ì…‹ 50,000ì¥, ê²€ì¦ì…‹ 10,000ì¥)\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "\n",
    "class_name = ('airplane', 'automobile', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ë°ì´í„° ì´ë¯¸ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL \n",
    "import numpy as np\n",
    "\n",
    "# ë°ì´í„° ì¤‘ ì¼ë¶€ë¥¼ ëœë¤ìœ¼ë¡œ ì„ íƒí•´ ì´ë¯¸ì§€ì™€ label í™•ì¸\n",
    "ROW = 3\n",
    "COLUMN = 3\n",
    "\n",
    "image_indexes = np.random.choice(len(np.array(X_train)), ROW * COLUMN)\n",
    "\n",
    "for i in range(ROW * COLUMN):\n",
    "    label_index = ((y_train[image_indexes][i])[0])\n",
    "    plt.subplot(ROW, COLUMN, 1+i)\n",
    "    plt.imshow(PIL.Image.fromarray(X_train[image_indexes][i]))\n",
    "    plt.title(\"%s\" % class_name[label_index])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ : Normalize 0~255 -> 0~1 \n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "print('X_train shape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils as utils\n",
    "\n",
    "# Label ì „ì²˜ë¦¬ : One hot encoding\n",
    "\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\ny_val:\\n\")\n",
    "print(y_test.shape)\n",
    "\n",
    "print('num_classes:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part2. Model Train\n",
    "### 4.CNN ëª¨ë¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "    \n",
    "# ëª¨ë¸ ìƒì„±/ë ˆì´ì–´ ìŒ“ê¸°\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(8, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape=(32, 32, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# ëª¨ë¸ compile\n",
    "sgd = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ëª¨ë¸ í›ˆë ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨\n",
    "history = model.fit(X_train, y_train,\n",
    "                 epochs=epochs,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part3. Model Evaluate and Save\n",
    "### 6. ëª¨ë¸ í‰ê°€ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ëœ ëª¨ë¸ í‰ê°€\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. ëª¨ë¸ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook ë””ë ‰í† ë¦¬ì— ëª¨ë¸ ì €ì¥\n",
    "model.save('keras_cifar10_trained_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part4. Vsualize Training\n",
    "### 8. í›ˆë ¨ ê³¼ì • ì‚´í´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part5. Test Model\n",
    "### 9. ëœë¤ ì´ë¯¸ì§€ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ì¦ ì…‹ ì¤‘ 3ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ëœë¤ìœ¼ë¡œ ì„ íƒí•´ í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
    "\n",
    "for index in np.random.choice(len(y_test), 3, replace = False):\n",
    "    predicted = model.predict(X_test[index:index + 1])[0]\n",
    "    label = y_test[index]\n",
    "    result_label = np.where(label == np.amax(label))\n",
    "    result_predicted = np.where(predicted == np.amax(predicted))\n",
    "\n",
    "    title = \"Label value = %s || Predicted value = %s \" % (class_name[result_label[0][0]], class_name[result_predicted[0][0]])\n",
    "    fig = plt.figure(1, figsize = (3,3))\n",
    "    ax1 = fig.add_axes((0,0,.8,.8))\n",
    "    ax1.set_title(title)\n",
    "    images = X_test\n",
    "    plt.imshow(images[index], cmap = plt.cm.gray_r, interpolation = 'nearest')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
